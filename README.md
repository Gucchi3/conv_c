# PureC-DL-Kernels
![Language](https://img.shields.io/badge/language-C99-blue)
![Platform](https://img.shields.io/badge/platform-Any%20%28x86%2FARM%2FRISC--V%29-green)
![Status](https://img.shields.io/badge/status-Active%20Development-orange)

## ğŸ“– Overview
A lightweight, zero-dependency C implementation of deep learning operators, targeting Convolutional Neural Networks (CNN), Vision Transformers (ViT), and State Space Models (Mamba/VMamba).

The goal is to achieve **maximum portability** across any processor architecture (x86, ARM, RISC-V, DSPs, MCUs) by using standard C99 without external libraries.

## ğŸš€ Key Features
- **Pure C implementation**: No C++, no heavy frameworks (PyTorch/TensorFlow).
- **Hardware Agnostic**: Compiles on any platform with a standard C compiler.
- **Embedded Optimization**: Efficient pointer arithmetic and memory management designed for resource-constrained devices.


## ğŸ—ºï¸ Development Roadmap
The project currently focuses on implementing a standard CNN. Advanced architectures like Mamba will be addressed in later phases.

1. **Phase 1: Basic CNN Implementation** (Current Focus)
   - Implement essential layers (Conv2d, Activation, Pooling, Linear).
2. **Phase 2: MCU Verification**
   - Verify operation on actual Microcontrollers (Arduino/STM32/ESP32...).
3. **Phase 3: Advanced Architectures**
   - Implement Vision Transformer (ViT) and Mamba (SSM) blocks.
4. **Phase 4: INT8 Quantization Support**
   - Develop INT8 quantized models and integer-only inference kernels to reduce memory usage and improve efficiency.
5. **Phase 5: Hardware-Specific SIMD Optimization**
   - Add SIMD instruction support for specific hardware (e.g., CV32E40P(PULP)) to accelerate inference speed.

## ğŸ“Š Implementation Status
ğŸš§ **Work in Progress**

| Category | Operator / Module | Status | Note |
| :--- | :--- | :---: | :--- |
| **Convolution** | Conv2d (HWC) | âœ… Done | Supports Stride, Padding, Bias |
||Conv2d_BN_ACT|âœ… Done| Conv2d(fused BN) + ACT|
| | **PConv2d** (Pointwise) | ğŸš« Suspended | Use `PConv2d_BN_ACT` instead. |
| | PConv2d_BN_ACT | â³ Todo | Header defined in `Conv2d.h` |
| | **DConv2d** (Depthwise) | ğŸš« Suspended | Use `DConv2d_BN_ACT` instead. |
| | DConv2d_BN_ACT | â³ Todo | Header defined in `Conv2d.h` |
| **Pooling** | **Max Pooling** | â³ Todo | Standard downsampling |
| | Average Pooling | â³ Todo | Less frequent usage |
| **Linear** | **Linear** | âœ… Done | Done! |
| **Normalization** | Batch Norm | ğŸš« Suspended | **Cancelled**: Fused into Conv via ONNX . |
| | Layer Norm | â³ Todo | Required for ViT / Mamba |
| **Activation** | **ReLU** | âœ… Done | |
| | RELU6 |âœ… Done||
| | SiLU | âœ… Done | Required for Mamba blocks |
| | Sigmoid | â³ Todo | |
| | Softmax | â³ Todo | |
| **Attention** | **Self-Attention (QKV)** | â³ Todo | Postponed until CNN is complete. |
| **Mamba**| **Efficient VMamba S6** | â³ Todo | Postponed until CNN is complete. |

## ğŸ›  Utilities (Python)

Tools to bridge the gap between PyTorch training and C inference.

| Tool | Function | Status | Note |
| :--- | :--- | :---: | :--- |
| **Weight Exporter** | `.pth` (PyTorch) $\to$ `.c` `.h` (C)  | ğŸš§ **Now** | Auto-generates `W_Tensor` / `B_Tensor` arrays |
|**Permute**|HWC -> CHW|â³ Todo|Auto permute HWC -> CHW|
||CHW -> HWC|â³ Todo|Auto permute CHW -> HWC|


## ğŸ›  Usage Example

ğŸš§ **Under Construction** ğŸš§

Release a "From PyTorch to C" tutorial once verification is complete.

## ğŸ—ï¸ Building & Compilation

You can compile this project using either **CMake** (Recommended) or **GCC**.

### âš™ï¸ Debug Mode Configuration
Before compiling, you can control the verbosity of the application using the `DEBUG` macro.

| Value | Mode | Description |
| :---: | :--- | :--- |
| **1** | **Debug** | Enables detailed logging and shape checking. |
| **0** | **Release** | Disables logging for maximum performance. |

---

### Option 1: Using CMake (Recommended)
CMake automatically handles dependencies and cross-platform build configurations.

1. **Configure** (Prepare the build directory):
   ```bash
   # Configure for Release mode (DEBUG=0)
   cmake -S . -B build -DCMAKE_C_FLAGS="-DDEBUG=0"
   ```
   *(Or simply `cmake -S . -B build` if you set the default in CMakeLists.txt)*

2. **Build** (Compile the source code):
   ```bash
   cmake --build build
   ```

3. **Run**:
   - **Windows**: `.\build\Debug\my_app.exe`
   - **Linux/Mac**: `./build/my_app`

---

### Option 2: Using GCC (Manual)
If you prefer running a single command without CMake, use the following gcc command. This compiles all .c source files and includes the necessary .h headers directories.

```bash
gcc -DDEBUG=0 -o my_app C_core/main.c C_core/src/core/*.c C_core/src/layers/*.c generated/weight.c -I C_core/include -I generated -lm
```

> **Note**: Ensure that `generated/weight.c weight.h and input.h` exists (generated by the Python exporter) before running this command.
## ğŸ“„ License

MiT License
